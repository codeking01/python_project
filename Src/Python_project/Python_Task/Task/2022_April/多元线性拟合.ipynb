{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# slope, intercept, r, p, std_err"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 开始预测\n",
    "# speed = myfunc(10)\n",
    "# print(speed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 多元线性拟合\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
    "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
    "# 三次函数\n",
    "mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n",
    "\n",
    "myline = numpy.linspace(1, 22, 100)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(myline, mymodel(myline))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "x = [1,2,3,5,6,7,8,9,10,12,13,14,15,16,18,19,21,22]\n",
    "y = [100,90,80,60,60,55,60,65,70,70,75,76,78,79,90,99,99,100]\n",
    "\n",
    "mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))\n",
    "# 计算拟合的结果r\n",
    "print(r2_score(y, mymodel(x)))\n",
    "# 计算预测值\n",
    "speed = mymodel(17)\n",
    "print(speed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import linear_model\n",
    "\n",
    "df = pandas.read_csv(\"cars.csv\")\n",
    "\n",
    "X = df[['Weight', 'Volume']]\n",
    "y = df['CO2']\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X.values, y)\n",
    "\n",
    "# 预测重量为 2300kg、排量为 1300ccm 的汽车的二氧化碳排放量：\n",
    "predictedCO2 = regr.predict([[2300, 1300]])\n",
    "\n",
    "print(predictedCO2)\n",
    "# 'Weight', 'Volume'的值 拟合的系数\n",
    "print(regr.coef_)\n",
    "# 这些值告诉我们，如果重量增加 1g，则 CO2 排放量将增加 0.00755095g。\n",
    "# 如果发动机尺寸（容积）增加 1 ccm，则 CO2 排放量将增加 0.00780526g。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 再次预测\n",
    "predictedCO2 = regr.predict([[3300, 1300]])\n",
    "print(predictedCO2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Python sklearn 模块有一个名为 StandardScaler() 的方法，该方法返回带有转换数据集方法的 Scaler 对象。处理后的数据聚集在均值为0的附近，标准差为1\n",
    "scale = StandardScaler()\n",
    "df = pandas.read_csv(\"cars.csv\")\n",
    "# 缩放 Volume 1000倍\n",
    "df['Volume'] = df['Volume'] / 1000\n",
    "X = df[['Weight', 'Volume']]\n",
    "y = df['CO2']\n",
    "# 返回带有转换数据集方法的 Scaler 对象。 归一化和标准化的类 在同一个数量级比较\n",
    "# X.values的均值和标准差，并应用在X.values上。\n",
    "scaledX = scale.fit_transform(X.values)\n",
    "# print(scaledX)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(scaledX, y)\n",
    "# 这个transform用的和上一个是同一个标准差，保持数据的一致性 数据返回这个转化好的数据列表\n",
    "scaled = scale.transform([[2300, 1.3]])\n",
    "\n",
    "predictedCO2 = regr.predict([scaled[0]])\n",
    "\n",
    "print('%.2f' % predictedCO2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "numpy.random.seed(2)\n",
    "# 我们的数据集展示了商店中的 100 位顾客及其购物习惯。x 轴表示购买前的分钟数。y 轴表示在购买上花费的金额。\n",
    "# loc为平均值，scale此概率分布的标准差，\n",
    "x = numpy.random.normal(loc=3,scale= 1,size= 100)\n",
    "y = numpy.random.normal(loc=150,scale= 40,size= 100) / x\n",
    "# 取到第80\n",
    "train_x = x[:80]\n",
    "train_y = y[:80]\n",
    "# 从第80开始\n",
    "test_x = x[80:]\n",
    "test_y = y[80:]\n",
    "\n",
    "mymodel = numpy.poly1d(numpy.polyfit(train_x, train_y, deg=4))\n",
    "# 用于在线性空间中以均匀步长生成数字序列。\n",
    "myline = numpy.linspace(0, 6,1000)\n",
    "\n",
    "plt.scatter(train_x, train_y)\n",
    "plt.plot(myline, mymodel(myline))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 查看查看训练拟合程度R方\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(train_y, mymodel(train_x))\n",
    "print(r2)\n",
    "# 查看测试的分数\n",
    "r3 = r2_score(test_y, mymodel(test_x))\n",
    "print(r3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 如果购买客户在商店中停留 5 分钟，她将花费多少钱？\n",
    "print(mymodel(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Python sklearn 模块有一个名为 StandardScaler() 的方法，该方法返回带有转换数据集方法的 Scaler 对象。处理后的数据聚集在均值为0的附近，标准差为1\n",
    "# scale = StandardScaler()\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "numpy.random.seed(2)\n",
    "# 我们的数据集展示了商店中的 100 位顾客及其购物习惯。x 轴表示购买前的分钟数。y 轴表示在购买上花费的金额。\n",
    "# loc为平均值，scale此概率分布的标准差，\n",
    "x = numpy.random.normal(loc=3,scale= 1,size= 100)\n",
    "y = numpy.random.normal(loc=150,scale= 40,size= 100) / x\n",
    "''' 将 y 转换成 列 '''\n",
    "import numpy as np\n",
    "# len(y)是行，1是列\n",
    "x = np.array(x).reshape(len(x),1)\n",
    "y = np.array(y).reshape(len(y),1)\n",
    "'''引入标准化函数'''\n",
    "from sklearn import preprocessing\n",
    "# 将数据的每一个特征缩放到给定的范围\n",
    "x_MinMax = preprocessing.MinMaxScaler()\n",
    "y_MinMax = preprocessing.MinMaxScaler()\n",
    "'''标准化'''\n",
    "x = x_MinMax.fit_transform(x)\n",
    "y = y_MinMax.fit_transform(y)\n",
    "# 取到第80\n",
    "train_x = x[:80]\n",
    "train_y = y[:80]\n",
    "# 从第80开始\n",
    "test_x = x[80:]\n",
    "test_y = y[80:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "fit1 = MLPRegressor(\n",
    "    hidden_layer_sizes=(100,50), activation='relu',solver='adam',\n",
    "    # '''第一个隐藏层有100个节点，第二层有50个，激活函数用relu，梯度下降方法用adam'''\n",
    "    alpha=0.01,max_iter=200)\n",
    "# '''惩罚系数为0.01，最大迭代次数为200'''\n",
    "print (\"fitting model right now\")\n",
    "# .ravel()可以把列向量转化为一个一维数组\n",
    "fit1.fit(train_x,train_y.ravel())\n",
    "pred1_train = fit1.predict(train_x)\n",
    "'''计算训练集 MSE'''\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_1 = mean_squared_error(pred1_train,train_y)\n",
    "print (\"Train ERROR = \", mse_1)\n",
    "'''计算测试集mse'''\n",
    "pred1_test = fit1.predict(test_x)\n",
    "mse_2 = mean_squared_error(pred1_test,test_y)\n",
    "print (\"Test ERROR = \", mse_2)\n",
    "'''结果可视化'''\n",
    "import matplotlib.pyplot as plt\n",
    "xx=range(0,len(test_y))\n",
    "train_xx=range(0,len(pred1_train))\n",
    "# figsize 设置显示的长，宽\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(xx,test_y,color=\"red\",label=\"Sample Point\",linewidth=3)\n",
    "plt.plot(xx,pred1_test,color=\"orange\",label=\"predict Line\",linewidth=2)\n",
    "# plt.plot(train_xx,pred1_train,color=\"red\",label=\"Fitting Line\",linewidth=3)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 计算预测的分数\n",
    "from sklearn.metrics import explained_variance_score\n",
    "score=explained_variance_score(pred1_test,test_y)\n",
    "print('evs: %.2f%%'%(score*100.0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 测试一个预测值\n",
    "my_xtest=[5.0]\n",
    "my_xtest = np.array(my_xtest).reshape(len(my_xtest),1)\n",
    "'''引入标准化函数'''\n",
    "from sklearn import preprocessing\n",
    "# 将数据的每一个特征缩放到给定的范围\n",
    "x_MinMax = preprocessing.MinMaxScaler()\n",
    "my_xtest = x_MinMax.fit_transform(my_xtest)\n",
    "my_test_predict = fit1.predict(my_xtest)\n",
    "my_test_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_xtest = np.array(x).reshape(len(my_xtest),1)\n",
    "'''引入标准化函数'''\n",
    "from sklearn import preprocessing\n",
    "# 将数据的每一个特征缩放到给定的范围\n",
    "x_MinMax = preprocessing.MinMaxScaler()\n",
    "my_xtest = x_MinMax.fit_transform(my_xtest)\n",
    "my_xtest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# scaledX = scale.fit_transform(mldata_x.values)\n",
    "\n",
    "#划分训练集和测试集合\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(mldata_x, mldata_y, test_size = 0.3, random_state = 5)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(scaledX, mldata_y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# solver 权重优化器  alpha 正则化项参数\n",
    "# learning_rate :学习率,用于权重更新,只有当solver为’sgd’时使用，{‘constant’，’invscaling’, ‘adaptive’},默认constant\n",
    "mp= MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5,2), random_state=1)\n",
    "mp.fit(train_x.ravel(), train_y.ravel())\n",
    "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
    "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
    "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "              nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "              solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "              warm_start=False)\n",
    "Predict = mp.predict(test_x)\n",
    "mp_Score = accuracy_score(test_y,Predict)\n",
    "mp_Score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(train_x, train_y)\n",
    "plt.plot(test_x, Predict)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}