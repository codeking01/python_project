{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import unique\n",
    "\n",
    "from src.OtherTasks.ML.PreDeal_Tools import Del_deletion_data, Record_usable_cols, Deal_sorted_Ydata, convert_to_num, \\\n",
    "    get_final_useablecols, all_ydata, delAndGetCols, get_merge_tabledata, deal_verify_ydata, get_former_Ydata\n",
    "import numpy as np\n",
    "# 这个pandas处理数据效果不太好 建议用numpy\n",
    "thedata = pd.read_excel(io='Data613.xlsx', sheet_name='数据标准化-建模用')\n",
    "Preddata = pd.read_excel(io='Data613.xlsx', sheet_name='数据标准化-预测用')\n",
    "\n",
    "# 获取数据表对象\n",
    "thedata = np.array(thedata)\n",
    "Preddata = np.array(Preddata)\n",
    "# 将表的内容 7个数据表 挨个处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[-1, 1, 2.2134, ..., -0.74466, 1.60837, '0'],\n        [-1, 1, 2.2134, ..., -0.74466, 0.94436, '0'],\n        [-1, 1, 0.72748, ..., -0.74466, 0.94436, '0'],\n        ...,\n        [2, -1, -0.01548, ..., 0.55961, 0.61235, '1'],\n        [2, -1, -0.01548, ..., 0.55961, 0.94436, '1'],\n        [2, -1, -0.01548, ..., 0.55961, 0.28034, '1']], dtype=object),\n [2, 3, 5, 7, 8, 22])"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取源建模的X数据 传入的对象是获取的excel对象\n",
    "FormerTwo_data, FormerThree_data, FormerFour_data, FormerFive_data, FormerSix_data, FormerSeven_data = get_merge_tabledata(thedata)\n",
    "# 获取预测的X数据\n",
    "Verify_TABLE_TWO, Verify_TABLE_THREE, Verify_TABLE_FOUR, Verify_TABLE_FIVE, Verify_TABLE_SIX, Verify_TABLE_SEVEN = get_merge_tabledata(Preddata)\n",
    "\n",
    "# 删除缺失值过多的行，并保存del_cols\n",
    "tempFormerTwo_data = delAndGetCols(FormerThree_data)\n",
    "base_Xdata = tempFormerTwo_data[0]\n",
    "del_cols = tempFormerTwo_data[1]\n",
    "# 用del_cols删除验证集X不需要的列\n",
    "Verify_Xdata = np.delete(Verify_TABLE_THREE, del_cols, axis=1)\n",
    "\n",
    "tempFormerTwo_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [],
   "source": [
    "# 获取源建模的数据Y_data\n",
    "Original_TableTwoYdata, Original_TableThreeYdata, Original_TableFiveYdata, Original_TableSixYdata, Original_TableSevenYdata=get_former_Ydata(thedata)\n",
    "# 获取预测数据的Y_data\n",
    "Predict_TableTwoYdata, Predict_TableThreeYdata, Predict_TableFiveYdata, Predict_TableSixYdata, Predict_TableSevenYdata=get_former_Ydata(Preddata)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "[8, 9, 10, 11, 12, 13, 14, 15, 16]"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将Y取出来，然后取出缺失值过多的列\n",
    "\n",
    "# 获取可用的列\n",
    "final_cols = get_final_useablecols(Original_TableThreeYdata, Predict_TableThreeYdata)\n",
    "final_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [],
   "source": [
    "# 获取可以用的Y_data\n",
    "Original_YdataList, Pred_YdataList = all_ydata(final_cols, Original_TableTwoYdata, Predict_TableTwoYdata)\n",
    "# todo 到时候遍历这个列表，然后依次计算,依次去建模预测\n",
    "# 建模的Y_data\n",
    "Modeling_Y_data = Original_YdataList[1]\n",
    "# 预测的Y_data\n",
    "Pred_Y_data = Pred_YdataList[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for index in range(len(Modeling_Y_data)):\n",
    "#     start_pred()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "# 先删除缺失值，然后再去将Y_data分类\n",
    "# 删除缺失值过多的行\n",
    "# 处理建模的X_data,Y_data\n",
    "temp_OriginalXdata = np.column_stack((base_Xdata, Modeling_Y_data))\n",
    "# 删除缺失的行\n",
    "temp_OriginalXdata = Del_deletion_data(temp_OriginalXdata, 0)\n",
    "X_data = temp_OriginalXdata[:, :-1]\n",
    "Y_data = temp_OriginalXdata[:, -1]\n",
    "# 处理验证的X_data,Y_data\n",
    "# 合并数据\n",
    "temp_verifydata = np.column_stack((Verify_Xdata, Pred_Y_data))\n",
    "# 删除缺失的行\n",
    "temp_verifydata = Del_deletion_data(temp_verifydata, 0)\n",
    "# 获取预测数据的X_data，Y_data\n",
    "X_verify_data = temp_verifydata[:, :-1]\n",
    "Y_verify_data = temp_verifydata[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "data": {
      "text/plain": "([], [])"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检验一下是否将所有的空值删除完毕，这个地方是用来做验证的 返回为空列表则删除成功！\n",
    "list(set(np.where(np.isnan(temp_OriginalXdata.astype(float)) == True)[0].tolist())), list(set(np.where(np.isnan(temp_verifydata.astype(float)) == True)[0].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "data": {
      "text/plain": "([array([-1, 0, 1], dtype=object), -2.24214, 0.77777],\n array([-1, 0, 1], dtype=object))"
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将建模Y_data分类(-1,0,1)，并且取出边界值\n",
    "Y_data,Y_data_boundsMin,Y_data_boundsMax=Deal_sorted_Ydata(Y_data)\n",
    "# 获取预测数据的Y_data Verify_Ydata = Pred_Y_data\n",
    "Verify_Ydata = deal_verify_ydata(Y_verify_data, Y_data_boundsMin, Y_data_boundsMax)\n",
    "# 查看是否替换成功\n",
    "[unique(Y_data),Y_data_boundsMin,Y_data_boundsMax],np.unique(Verify_Ydata)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "# 切分训练数据和测试数据\n",
    "from sklearn.model_selection import train_test_split\n",
    "## 30%测试数据，70%训练数据，stratify=y表示训练数据和测试数据具有相同的类别比例\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=2, stratify=Y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rfc_acc准确率: 0.9\n",
      "Gbc_acc准确率: 0.9\n",
      "SVC准确率： 0.9\n",
      "KNC准确率： 0.88\n",
      "ABC准确率： 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\All_Softwares\\Develop_Tools\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN准确率： 0.9\n",
      "CNN准确率： 0.9\n",
      "LDA准确率： 0.88\n",
      "QDA准确率： 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\All_Softwares\\Develop_Tools\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\All_Softwares\\Develop_Tools\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# 开始训练模型\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# 获取模型  随机森林\n",
    "Rfc = RandomForestClassifier()\n",
    "Rfc.fit(X_train, y_train.astype(float))\n",
    "Rfc_pred = Rfc.predict(X_test)\n",
    "Rfc_acc= accuracy_score(y_test.astype(float), Rfc_pred)\n",
    "print('Rfc_acc准确率:', Rfc_acc)\n",
    "\n",
    "# 梯度提升树\n",
    "Gbc = GradientBoostingClassifier()\n",
    "Gbc.fit(X_train, y_train.astype(float))\n",
    "Gbc_pred = Gbc.predict(X_test)\n",
    "Gbc_acc=accuracy_score(y_test.astype(float), Gbc_pred)\n",
    "print('Gbc_acc准确率:',Gbc_acc)\n",
    "\n",
    "# 使用SVM模型\n",
    "from sklearn.svm import SVC\n",
    "Svc = SVC()\n",
    "Svc.fit(X_train, y_train.astype(float))\n",
    "Svc_pred = Svc.predict(X_test)\n",
    "Svc_acc = accuracy_score(y_test.astype(float), Svc_pred)\n",
    "print('SVC准确率：', Svc_acc)\n",
    "\n",
    "# 使用KNN模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "Knc = KNeighborsClassifier()\n",
    "Knc.fit(X_train, y_train.astype(float))\n",
    "Knc_pred = Knc.predict(X_test)\n",
    "Knc_acc = accuracy_score(y_test.astype(float), Knc_pred)\n",
    "print('KNC准确率：', Knc_acc)\n",
    "\n",
    "# 使用AdaBoost模型\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Abc = AdaBoostClassifier()\n",
    "Abc.fit(X_train, y_train.astype(float))\n",
    "Abc_pred = Abc.predict(X_test)\n",
    "Abc_acc = accuracy_score(y_test.astype(float), Abc_pred)\n",
    "print('ABC准确率：', Abc_acc)\n",
    "\n",
    "# 使用DNN模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "Dnn = MLPClassifier()\n",
    "Dnn.fit(X_train, y_train.astype(float))\n",
    "Dnn_pred = Dnn.predict(X_test)\n",
    "Dnn_acc = accuracy_score(y_test.astype(float), Dnn_pred)\n",
    "print('DNN准确率：', Dnn_acc)\n",
    "\n",
    "# 使用卷积神经网络模型\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "CNN = MLPClassifier()\n",
    "CNN.fit(X_train, y_train.astype(float))\n",
    "CNN_pred = CNN.predict(X_test)\n",
    "CNN_acc = accuracy_score(y_test.astype(float), CNN_pred)\n",
    "print('CNN准确率：', CNN_acc)\n",
    "\n",
    "# 使用LDA模型\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "Lda = LinearDiscriminantAnalysis()\n",
    "Lda.fit(X_train, y_train.astype(float))\n",
    "Lda_pred = Lda.predict(X_test)\n",
    "Lda_acc = accuracy_score(y_test.astype(float), Lda_pred)\n",
    "print('LDA准确率：', Lda_acc)\n",
    "\n",
    "# 使用QDA模型\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "Qda = QuadraticDiscriminantAnalysis()\n",
    "Qda.fit(X_train, y_train.astype(float))\n",
    "Qda_pred = Qda.predict(X_test)\n",
    "Qda_acc = accuracy_score(y_test.astype(float), Qda_pred)\n",
    "print('QDA准确率：', Qda_acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "for i in range(Rfc_pred.shape[0]):\n",
    "    if y_test[i] == Rfc_pred[i]:\n",
    "        k += 1\n",
    "k / y_test.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gbc 0.7386363636363636\n",
      "Rfc 0.7386363636363636\n",
      "Svc 0.7386363636363636\n",
      "Knc 0.7386363636363636\n",
      "Abc 0.3693181818181818\n",
      "Dnn 0.7386363636363636\n",
      "CNN 0.7386363636363636\n",
      "Lda 0.7329545454545454\n",
      "Qda 0.7386363636363636\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 预测数据\n",
    "Rfc_pred = Rfc.predict(X_verify_data)\n",
    "Gbc_pred = Gbc.predict(X_verify_data)\n",
    "Svc_pred = Svc.predict(X_verify_data)\n",
    "Knc_pred = Knc.predict(X_verify_data)\n",
    "Abc_pred = Abc.predict(X_verify_data)\n",
    "Dnn_pred = Dnn.predict(X_verify_data)\n",
    "CNN_pred = CNN.predict(X_verify_data)\n",
    "Lda_pred = Lda.predict(X_verify_data)\n",
    "Qda_pred = Qda.predict(X_verify_data)\n",
    "# 计算准确率\n",
    "verify_y1 = accuracy_score(Y_verify_data.astype(float), Rfc_pred)\n",
    "verify_y2 = accuracy_score(Y_verify_data.astype(float), Gbc_pred)\n",
    "verify_y3 = accuracy_score(Y_verify_data.astype(float), Svc_pred)\n",
    "verify_y4 = accuracy_score(Y_verify_data.astype(float), Knc_pred)\n",
    "verify_y5 = accuracy_score(Y_verify_data.astype(float), Abc_pred)\n",
    "verify_y6 = accuracy_score(Y_verify_data.astype(float), Dnn_pred)\n",
    "verify_y7 = accuracy_score(Y_verify_data.astype(float), CNN_pred)\n",
    "verify_y8 = accuracy_score(Y_verify_data.astype(float), Lda_pred)\n",
    "verify_y9 = accuracy_score(Y_verify_data.astype(float), Qda_pred)\n",
    "\n",
    "print('Gbc', verify_y1)\n",
    "print('Rfc', verify_y2)\n",
    "print('Svc', verify_y3)\n",
    "print('Knc', verify_y4)\n",
    "print('Abc', verify_y5)\n",
    "print('Dnn', verify_y6)\n",
    "print('CNN', verify_y7)\n",
    "print('Lda', verify_y8)\n",
    "print('Qda', verify_y9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}